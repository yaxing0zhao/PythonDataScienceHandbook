# Notes on Python Data Science Handbook

[Python Data Science Handbook](https://github.com/yaxing0zhao/PythonDataScienceHandbook/tree/master/notebooks)

## ipython

### 01:00
ipython, jupyter

### 01:01
`sum?`

### 01:02
shortcuts: ctrl+l:Clear terminal screen

### 01:03
**magic commands**: `%paste, %run pyscirpt.py, %timeit, %lsmagic `

### 01:04
`%history`

### 01:05
`!`

### 01:06
`%xmode, %debug, %pdb`

### 01:07

- `%time`: Time the execution of a single statement

- `%timeit`: Time repeated execution of a single statement for more accuracy

- `%prun`: Run code with the profiler

- `%lprun`: Run code with the line-by-line profiler

- `%memit`: Measure the memory use of a single statement

- `%mprun`: Run code with the line-by-line memory profiler

  

## NumPy

### 02:01
æ‰¹é‡åˆ›å»º**array**ï¼Œ `np.arrange(10).reshape((2,5))`

### 02:02
 arrayæ“ä½œï¼Œ`a1.ndim, a1.shape, a1.size, a1.dtype` 
            å­é›†ï¼Œ`a1[:,0]` 
            æ“ä½œ`a1.copy()ï¼Œa1.reshape((nrow, ncol))ï¼Œ
            np.concatenate([a1,a2], axis=1)` (cbind, rbind, append), 
            splitting: `np.vsplit(a1, [2]), np.hsplit(a1, [2]).`

### 02:03
NumPy ä¸­å‘é‡åŒ–æ“ä½œï¼Œå„ç§æ•°å­¦è¿ç®—ï¼Œå‡å°‘ä½¿ç”¨functionså’Œloopã€‚

### 02:04
ç»Ÿè®¡è¿ç®—ï¼ŒNumPyä¸­å‡½æ•°æ¯”pythonè‡ªå¸¦å‡½æ•°è¦å¿« `np.sum()`ï¼arrayä¸Šçš„ç»Ÿè®¡è¿ç®—ã€‚

### 02:05
arrayå‘é‡é—´æ“ä½œã€‚

### 02:06
arrayé€»è¾‘æ“ä½œï¼Œæ˜¯å¦`&, |, ~, ^, bool(24 & 59)`ï¼Œæ¯”è¾ƒ

### 02:07
fancy index: æ‰¹é‡é€‰å–å­é›† `list[idx], array[row_idx, col_idx]`, å„ç§é€‰å–æ–¹æ³•â€¦â€¦

### 02:08
sorting arrayï¼šæ’åºåŠéƒ¨åˆ†æ’åº`np.sort(a1, axis=0)`, `np.argsort(a1)`return args index. 
              éƒ¨åˆ†æ’åº`np.partition(a1, 3, axis=1)`

### 02:09
structured array: similar to dataframe in pandas



## Pandas

### 03:01 
**series and dataframe** åˆ›å»º, index, `df1.shape()`(dim(df1))

### 03:02
series and dataframe å­é›†é€‰å–`df1.iloc[:nrow, :ncol], df1[colname]`

### 03:03
dataframe æ•°å­¦è¿ç®—ï¼Œè‡ªåŠ¨å¯¹é½æˆ–äº§ç”ŸNA, `a.add(b, fill_value=fill)` ã€‚

### 03:04
missing value: `np.nan(),df1.isnull(),df1.notnull(), df1.ffill(), df1.bfill(),df1.droupna(axis = 'colums')`

### 03:05
multi-index: dataframe ğŸ”›series by `stack()`, multi-index dataframe å–å­é›†æ—¶index must be sorted. 
              `reset_index() `ç›¸å½“äºmelt: multi-index to index, `reverse is set_index()`.

### 03:06
df combination: np.concatenate( see 02:02), 
                `pd.concat(df1, df2)`: å‚æ•°é€‰é¡¹ç±»ä¼¼mySQLã€‚`
                df1.append(df2)`ç±»ä¼¼rbind()

### 03:07
merge and join: `pd.merge(df1,df2, left_on='keyword1', right_on='keyword2', on='keyword3', suffixes=["_L", "_R"])'),
                  df1.join(df2)` ç›¸å½“äºSQLä¸­çš„joinã€‚

### 03:08
groupby: `df1.mean(axis='columns')`, `df1.describe() `,
          `df1.groupby('key').sum(), 
          df1.groupby('key').aggregate(['min', np.median, max]), 
          df1.groupby('key').apply(fun),`,  
          `filter(), transform() and apply()`:ç±»ä¼¼apply in R. 
          `df1.groupby(mapping).sum()`: replace a_idx with b_idx.

### 03:09
pivot table: å¤šå˜é‡groupby çš„ç®€åŒ–ç‰ˆã€‚
                `df1.pivot_table(data, values=None, index=None, columns=None, aggfunc={'survived':sum, 'fare':'mean'},
                fill_value=None, margins=False, dropna=True, margins_name='All')` 
              ` pivot_table(), pd.cut()`, ***åº”ç”¨å®ä¾‹***ã€‚

### 03:10
stringï¼šæ–‡æœ¬æ“ä½œå’ŒRç±»ä¼¼åŠŸèƒ½ï¼Œ`mystr.str.len()` ***åº”ç”¨å®ä¾‹***ã€‚

### 03:11
time; pd.datatime and pd.datautil, pd.tseries.offsets module. Np.array(), ***åº”ç”¨å®ä¾‹***ã€‚

### 03:12
**high-performance**: numexpr.evaluate() for compound expression, `pd.eval()` is faster. `Query()` for filter operation.



## Matplotlib

### 04:01
matplotlib: style, `plt.plot(x,y,color='red', linetype='solid', lable='linelable')`('-r', '-ok') , 
                    ylim,xlim: `plt.xlim(n1, n2), plt.axis([x1,x2,y1,y2])` 
                    title: `plt.title('title')`
                    `plt.legend(numpoints=1)`
                    `plt.colorbar()`
                    `plt.errorbar(x,y,yerr=dy, fmt='.k', color='red',ecolor='lightgray', elinewidth=3, capsize=0)`
                    `plt.fill_between(x, y-dy, y+dy, color='gray',alpha=0.2)`
                    å‚è€ƒçº¿`plt.axvline(0, color='k',linetype='--')`
                    æ¡å½¢å›¾`plt.hist(cmap='Blues')`
                    `ax.set()`
                     `put.show() `åªåœ¨æœ«å°¾ä¸€æ¬¡å°±å¥½ã€‚
                     ä¿å­˜`fig.savefig(filename.png).`
                     å¤šå›¾å¸ƒå±€`plt.subplot(2,1,1) #(row, col, panel number)` ã€‚

### 04:02
lineplot: åæ ‡è½´ï¼Œå›¾ä¾‹

### 04:03
scatter plot: å¤§æ•°æ®é¦–é€‰`plt.plot()`.

### 04:04
error bar: åŒ…æ‹¬è¿ç»­errorã€‚

### 04:05
å¯†åº¦å›¾`plt.contour(x,y,z)`å’Œè½®å»“å›¾ã€‚

### 04:10
ä¿®æ”¹åæ ‡è½´

### 04:14
**seaborn** ä¸»é¢˜ç”»å›¾æ›´ç¾è§‚ï¼Œç”¨å®ƒï¼å’Œggplot2å·®ä¸å¤šã€‚
            `import seaborn as sns
            sns.set(), sns.axes_style(style='ticks')`
            pair plot`sns.pairplot(iris, hue='species', size=2.5)`
            `sns.joinplot()`



## ML

### 05:02
array: sample * feature. Target col is the predicted class/feature. **MLçš„åŸºæœ¬æ­¥éª¤**ï¼šimport/instantiate/fit/predict. Linear regression, GaussianNB, across-validation, PCA, GMM cluster, hand-written digits, Isomap (dimensionality reduction) å®ä¾‹ã€‚

### 05:03
**cross-validation**ï¼Œ validation-curve, learning_curve

### 05:04
feature engineering: categorical, text, image, derived features, missing value imputation.

### 05:05
naive bayes: multi-NB

### 05:06
linear regression, regularization

### 05:07
SVA

### 05:08
RF

### 05:09
PCA: tends to be highly affected by outliers, `RandomizedPCA` and `SparsePCA`

### 05:10
manifold learning: multidimensional scaling (MDS), locally linear embedding (LLE), and isometric mapping (IsoMap).

### 05:11
k-means

### 05:12
gaussian mixtures

### 05:13
kernel density estimation

### 05:14
image features
